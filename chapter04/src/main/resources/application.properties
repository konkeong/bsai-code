spring.config.import=file:../.env[.properties]

spring.ai.openai.api-key=${OPENAPI_API_KEY}

# https://platform.openai.com/playground/tts

# The name of the model to use. tts-1 and tts-1-hd are both available.
# gpt-4o-mini-tts, tts-1, tts-1-1106, tts-1-hd, tts-1-hd-1106
spring.ai.openai.audio.speech.options.model=tts-1

# The voice to use for the TTS output. Available options are alloy , echo , fable , onyx , nova , and shimmer .
# Alloy, Ash, Ballad, Coral, Echo, Fable, Onyx, Nova, Sage, Shimmer, Verse
spring.ai.openai.audio.speech.options.voice=onyx

# The format of the audio output, supported formats are mp3 , opus , aac , flac , wav , and pcm .
# MP3, Optus, AAC, FLAC, WAV, PCM
spring.ai.openai.audio.speech.options.response-format=mp3

# The speed of the voice synthesis between 0.0 and 1.0 .
# range from 0.25 to 4.0
spring.ai.openai.audio.speech.options.speed=1.0

# ID of the model to use. Only whisper-1 (which is powered by our open source Whisper V2 model) is currently available.
# spring.ai.openai.audio.transcription.options.model=

# The format of the transcript output, in one of these options: json , text , srt , verbose_json , or vtt .
spring.ai.openai.audio.transcription.options.response-format=text

# The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.
spring.ai.openai.audio.transcription.options.temperature=0.5

# The timestamp granularities to populate for this transcription.
# response_format must be set verbose_json to use timestamp granularities.
# Either or both of these options are supported: word or segment.
# Note: There is no additional latency for segment timestamps,
# but generating word timestamps incurs additional latency.
# spring.ai.openai.audio.transcription.options.timestamp_granularities=

spring.ai.retry.max-attempts=3
